import asyncio
import logging
import logging.handlers
from pathlib import Path
from typing import List, Optional, Set, Tuple

from apscheduler.schedulers.asyncio import AsyncIOScheduler

from .bot.bot import TelegramBot
from .cache import get_cache, AppCache
from .config import AppConfig, ConfigManager, SourceType
from .database import Database
from .matcher.keyword import KeywordMatcher
from .models import Post
from .source import BaseSource, RSSSource, DiscourseSource
from .web import test_cookie


def setup_logging(log_dir: Optional[Path] = None) -> None:
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ

    - è¾“å‡ºåˆ° stdoutï¼ˆä¾› journald æ”¶é›†ï¼‰
    - è¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆæŒ‰å¤©è½®è½¬ï¼Œä¿ç•™30å¤©ï¼‰
    """
    log_format = "%(asctime)s - %(levelname)s - %(message)s"
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)

    # æ¸…é™¤å·²æœ‰çš„ handlersï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
    root_logger.handlers.clear()

    # Handler 1: stdoutï¼ˆä¾› systemd/journaldï¼‰
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(logging.Formatter(log_format))
    root_logger.addHandler(stream_handler)

    # Handler 2: æ–‡ä»¶ï¼ˆæŒ‰å¤©è½®è½¬ï¼‰
    if log_dir:
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / "app.log"
        file_handler = logging.handlers.TimedRotatingFileHandler(
            filename=log_file,
            when="midnight",      # æ¯å¤©åˆå¤œè½®è½¬
            interval=1,
            backupCount=30,       # ä¿ç•™30å¤©
            encoding="utf-8"
        )
        file_handler.setFormatter(logging.Formatter(log_format))
        file_handler.suffix = "%Y-%m-%d"  # å¤‡ä»½æ–‡ä»¶åç¼€æ ¼å¼
        root_logger.addHandler(file_handler)


# é»˜è®¤åˆå§‹åŒ–ï¼ˆä»… stdoutï¼Œæ–‡ä»¶æ—¥å¿—åœ¨ main ä¸­é…ç½®ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Suppress noisy httpx logs
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("apscheduler").setLevel(logging.WARNING)

# Batch sending configuration
BATCH_SIZE = 25  # Number of messages to send concurrently
BATCH_INTERVAL = 1.0  # Seconds between batches (Telegram rate limit ~30/sec)


def create_source(config: AppConfig) -> BaseSource:
    """Factory function to create data source based on config"""
    if config.source_type == SourceType.DISCOURSE:
        if not config.discourse_cookie:
            raise ValueError("Discourse source requires cookie configuration")
        return DiscourseSource(
            base_url=config.discourse_url,
            cookie=config.discourse_cookie,
            flaresolverr_url=config.flaresolverr_url
        )
    else:
        return RSSSource(url=config.rss_url)


class Application:
    """Main application that orchestrates all components"""

    def __init__(self, config: AppConfig, db_path: Path, config_manager: Optional[ConfigManager] = None):
        self.config = config
        self.config_manager = config_manager
        self.db_path = db_path
        self.db = Database(db_path)
        self.bot = TelegramBot(config.bot_token, self.db)
        self.source = create_source(config)
        self.matcher = KeywordMatcher()
        self.scheduler = AsyncIOScheduler()
        self.cache = get_cache()
        self._cookie_fail_count = 0  # è¿ç»­å¤±è´¥è®¡æ•°å™¨
        self._cookie_fail_threshold = 5  # è¿ç»­å¤±è´¥é˜ˆå€¼
        self._cookie_notify_round = 0  # ç¬¬å‡ è½®é€šçŸ¥
        self._fetch_fail_count = 0  # æ‹‰å–å¤±è´¥è®¡æ•°å™¨
        self._fetch_fail_threshold = 5  # æ‹‰å–è¿ç»­å¤±è´¥é˜ˆå€¼
        self._fetch_fail_notified = False  # æ˜¯å¦å·²å‘é€æ‹‰å–å¤±è´¥å‘Šè­¦

    def reload_config(self):
        """Hot reload configuration"""
        if not self.config_manager:
            logger.warning("æ— æ³•çƒ­æ›´æ–°ï¼šConfigManager æœªè®¾ç½®")
            return

        new_config = self.config_manager.load()
        if not new_config:
            logger.error("çƒ­æ›´æ–°å¤±è´¥ï¼šæ— æ³•åŠ è½½é…ç½®")
            return

        # Update source
        self.config = new_config
        self.source = create_source(new_config)
        # Reset cookie invalid state on config reload
        self._cookie_fail_count = 0
        self._cookie_notify_round = 0
        # Invalidate cache on config change
        self.cache.clear_all()
        logger.info(f"ğŸ”„ é…ç½®å·²çƒ­æ›´æ–°ï¼Œæ•°æ®æº: {self.source.get_source_name()}")

    async def _notify_admin(self, message: str) -> None:
        """Send notification to admin"""
        if not self.config.admin_chat_id:
            logger.warning("ç®¡ç†å‘˜ chat_id æœªé…ç½®ï¼Œæ— æ³•å‘é€å‘Šè­¦")
            return

        try:
            await self.bot.send_admin_alert(self.config.admin_chat_id, message)
            logger.info(f"ğŸ“¢ å·²å‘é€ç®¡ç†å‘˜å‘Šè­¦")
        except Exception as e:
            logger.error(f"å‘é€ç®¡ç†å‘˜å‘Šè­¦å¤±è´¥: {e}")

    def _check_cookie_valid(self) -> dict:
        """Check if discourse cookie is valid

        Returns:
            dict with keys:
            - valid: bool
            - error_type: "cookie_invalid" | "service_error" | None
            - error: str | None
        """
        if self.config.source_type != SourceType.DISCOURSE:
            return {"valid": True, "error_type": None, "error": None}

        if not self.config.discourse_cookie:
            return {"valid": False, "error_type": "cookie_invalid", "error": "Cookie æœªé…ç½®"}

        result = test_cookie(self.config.discourse_cookie, self.config.discourse_url, self.config.flaresolverr_url)
        return result

    def _fallback_to_rss(self) -> BaseSource:
        """Create RSS fallback source (deprecated, kept for compatibility)"""
        return RSSSource(url=self.config.rss_url)

    async def _check_cookie_task(self) -> None:
        """ç‹¬ç«‹çš„ Cookie æ£€æµ‹ä»»åŠ¡"""
        if self.config.source_type != SourceType.DISCOURSE:
            return

        # è¿ç»­æµ‹è¯• 3 æ¬¡
        fail_count = 0
        last_result = None
        for i in range(3):
            result = self._check_cookie_valid()
            last_result = result
            if not result.get("valid", False):
                fail_count += 1
                if i < 2:  # å‰ä¸¤æ¬¡å¤±è´¥åç­‰å¾… 2 ç§’å†è¯•
                    await asyncio.sleep(2)
            else:
                break

        if fail_count == 3:
            error_type = last_result.get("error_type", "unknown") if last_result else "unknown"
            error_msg = last_result.get("error", "æœªçŸ¥é”™è¯¯") if last_result else "æœªçŸ¥é”™è¯¯"

            # æœåŠ¡é”™è¯¯ï¼ˆFlareSolverr è¶…æ—¶ç­‰ï¼‰åªè®°å½•æ—¥å¿—ï¼Œä¸å‘å‘Šè­¦
            # å› ä¸º fetch_and_notify å·²ç»æœ‰å‘Šè­¦é€»è¾‘äº†
            if error_type == "service_error":
                logger.warning(f"âš ï¸ Cookie æ£€æµ‹å¤±è´¥ï¼ˆæœåŠ¡é”™è¯¯ï¼‰: {error_msg}")
                return

            # Cookie çœŸæ­£å¤±æ•ˆæ‰å‘å‘Šè­¦
            self._cookie_fail_count += 1
            logger.warning(f"âš ï¸ Cookie è¿ç»­ 3 æ¬¡æ£€æµ‹å¤±è´¥ï¼ˆç¬¬ {self._cookie_fail_count} è½®ï¼‰: {error_msg}")
            for i in range(1, 4):
                await self._notify_admin(
                    f"âš ï¸ Cookie å¯èƒ½å·²å¤±æ•ˆï¼ˆç¬¬ {self._cookie_fail_count} è½®é€šçŸ¥ï¼Œç¬¬ {i}/3 éï¼‰\n\n"
                    f"Discourse Cookie è¿ç»­ 3 æ¬¡éªŒè¯å¤±è´¥ã€‚\n"
                    f"é”™è¯¯ä¿¡æ¯: {error_msg}\n\n"
                    f"å½“å‰ä»å¯æ‹‰å–å…¬å¼€æ•°æ®ï¼Œä½†éƒ¨åˆ†é™åˆ¶å†…å®¹å¯èƒ½æ— æ³•è·å–ã€‚\n\n"
                    f"{'â—' * i} è¯·æ£€æŸ¥ Cookie æ˜¯å¦éœ€è¦æ›´æ–° {'â—' * i}\n\n"
                    f"æ›´æ–°æ–¹å¼ï¼šè®¿é—®é…ç½®é¡µé¢æ›´æ–° Cookie"
                )
        else:
            # æ£€æµ‹é€šè¿‡
            if self._cookie_fail_count > 0:
                logger.info(f"âœ… Cookie æ£€æµ‹æ¢å¤æ­£å¸¸ï¼ˆä¹‹å‰å¤±è´¥ {self._cookie_fail_count} è½®ï¼‰")
                await self._notify_admin("âœ… Cookie å·²æ¢å¤æœ‰æ•ˆï¼Œä¹‹å‰çš„å‘Šè­¦å¯ä»¥å¿½ç•¥äº†")
                self._cookie_fail_count = 0

    def _get_keywords_cached(self) -> List[str]:
        """Get keywords with caching"""
        cached = self.cache.get_keywords()
        if cached is not None:
            return cached
        keywords = self.db.get_all_keywords()
        self.cache.set_keywords(keywords)
        return keywords

    def _get_subscribe_all_users_cached(self) -> List[int]:
        """Get subscribe_all users with caching"""
        cached = self.cache.get_subscribe_all_users()
        if cached is not None:
            return cached
        users = self.db.get_all_subscribe_all_users()
        self.cache.set_subscribe_all_users(users)
        return users

    def _get_subscribers_cached(self, keyword: str) -> List[int]:
        """Get subscribers for a keyword with caching"""
        cached = self.cache.get_subscribers(keyword)
        if cached is not None:
            return cached
        subscribers = self.db.get_subscribers_by_keyword(keyword)
        self.cache.set_subscribers(keyword, subscribers)
        return subscribers

    def _get_subscribed_authors_cached(self) -> List[str]:
        """Get subscribed authors with caching"""
        cached = self.cache.get_authors()
        if cached is not None:
            return cached
        authors = self.db.get_all_subscribed_authors()
        self.cache.set_authors(authors)
        return authors

    def _get_author_subscribers_cached(self, author: str) -> List[int]:
        """Get subscribers for an author with caching"""
        cached = self.cache.get_author_subscribers(author)
        if cached is not None:
            return cached
        subscribers = self.db.get_subscribers_by_author(author)
        self.cache.set_author_subscribers(author, subscribers)
        return subscribers

    async def _send_batch(self, tasks: List[Tuple]) -> int:
        """Send a batch of notifications concurrently.

        Args:
            tasks: List of (chat_id, post, keyword_or_none) tuples

        Returns:
            Number of successfully sent notifications
        """
        if not tasks:
            return 0

        async def send_one(chat_id: int, post: Post, keyword: Optional[str]) -> bool:
            try:
                if keyword:
                    success = await self.bot.send_notification(
                        chat_id, post.title, post.link, keyword
                    )
                else:
                    success = await self.bot.send_notification_all(
                        chat_id, post.title, post.link
                    )
                if success:
                    # Record notification in DB
                    self.db.add_notification(chat_id, post.id, keyword or "__ALL__")
                return success
            except Exception as e:
                logger.error(f"å‘é€å¤±è´¥ {chat_id}: {e}")
                return False

        # Execute batch concurrently
        results = await asyncio.gather(
            *[send_one(chat_id, post, keyword) for chat_id, post, keyword in tasks],
            return_exceptions=True
        )

        success_count = sum(1 for r in results if r is True)
        return success_count

    async def fetch_and_notify(self) -> None:
        """Fetch posts and send notifications"""
        try:
            # Always use the configured source (no fallback to RSS)
            logger.info(f"ğŸ“¡ å¼€å§‹æ‹‰å–æ•°æ® ({self.source.get_source_name()})...")
            posts = self.source.fetch()

            # Use cached data
            keywords = self._get_keywords_cached()
            subscribe_all_users = self._get_subscribe_all_users_cached()
            subscribe_all_set: Set[int] = set(subscribe_all_users)
            subscribed_authors = self._get_subscribed_authors_cached()

            new_posts = []
            pending_tasks: List[Tuple] = []  # (chat_id, post, keyword_or_none)

            for post in posts:
                # Skip if post already processed
                if self.db.post_exists(post.id):
                    continue

                new_posts.append(post)
                self.db.add_post(post)

                # Track users already notified for this post (in this cycle)
                notified_users: Set[int] = set()

                # Collect subscribe_all notifications
                for chat_id in subscribe_all_users:
                    # Check DB for existing notification
                    if self.db.notification_exists_for_post(chat_id, post.id):
                        notified_users.add(chat_id)
                        continue
                    pending_tasks.append((chat_id, post, None))
                    notified_users.add(chat_id)

                # Collect author-based notifications
                if post.author and subscribed_authors:
                    author_lower = post.author.lower()
                    if author_lower in [a.lower() for a in subscribed_authors]:
                        subscribers = self._get_author_subscribers_cached(author_lower)
                        for chat_id in subscribers:
                            # Skip if already notified
                            if chat_id in notified_users:
                                continue
                            if chat_id in subscribe_all_set:
                                continue
                            if self.db.notification_exists_for_post(chat_id, post.id):
                                notified_users.add(chat_id)
                                continue
                            # Use special keyword format for author subscription
                            pending_tasks.append((chat_id, post, f"@{post.author}"))
                            notified_users.add(chat_id)

                # Collect keyword-based notifications
                if keywords:
                    matched_keywords = self.matcher.find_matching_keywords(post, keywords)

                    for keyword in matched_keywords:
                        subscribers = self._get_subscribers_cached(keyword)

                        for chat_id in subscribers:
                            # Skip if already notified (subscribe_all or another keyword)
                            if chat_id in notified_users:
                                continue
                            # Skip if already in subscribe_all
                            if chat_id in subscribe_all_set:
                                continue
                            # Check DB for existing notification for this post
                            if self.db.notification_exists_for_post(chat_id, post.id):
                                notified_users.add(chat_id)
                                continue

                            pending_tasks.append((chat_id, post, keyword))
                            notified_users.add(chat_id)

            # Send notifications in batches
            total_sent = 0
            for i in range(0, len(pending_tasks), BATCH_SIZE):
                batch = pending_tasks[i:i + BATCH_SIZE]
                sent = await self._send_batch(batch)
                total_sent += sent

                if sent > 0:
                    logger.info(f"  ğŸ“¤ æ‰¹é‡å‘é€ {sent}/{len(batch)} æ¡")

                # Rate limit between batches
                if i + BATCH_SIZE < len(pending_tasks):
                    await asyncio.sleep(BATCH_INTERVAL)

            # Summary log
            logger.info(f"âœ… æ‹‰å–å®Œæˆ: å…± {len(posts)} æ¡, æ–°å¢ {len(new_posts)} æ¡, æ¨é€ {total_sent} æ¡é€šçŸ¥")

            # æ‹‰å–æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°
            if self._fetch_fail_count > 0:
                logger.info(f"âœ… æ•°æ®æ‹‰å–æ¢å¤æ­£å¸¸ï¼ˆä¹‹å‰è¿ç»­å¤±è´¥ {self._fetch_fail_count} æ¬¡ï¼‰")
                if self._fetch_fail_notified:
                    await self._notify_admin("âœ… æ•°æ®æ‹‰å–å·²æ¢å¤æ­£å¸¸ï¼Œä¹‹å‰çš„å‘Šè­¦å¯ä»¥å¿½ç•¥äº†")
                self._fetch_fail_count = 0
                self._fetch_fail_notified = False

        except Exception as e:
            self._fetch_fail_count += 1
            logger.error(f"âŒ æ•°æ®æ‹‰å–å¤±è´¥ (ç¬¬ {self._fetch_fail_count} æ¬¡): {e}")

            # è¿ç»­å¤±è´¥è¾¾åˆ°é˜ˆå€¼æ—¶å‘é€å‘Šè­¦
            if self._fetch_fail_count >= self._fetch_fail_threshold and not self._fetch_fail_notified:
                self._fetch_fail_notified = True
                await self._notify_admin(
                    f"âš ï¸ æ•°æ®æ‹‰å–è¿ç»­å¤±è´¥ {self._fetch_fail_count} æ¬¡\n\n"
                    f"é”™è¯¯ä¿¡æ¯: {e}\n\n"
                    f"è¯·æ£€æŸ¥:\n"
                    f"1. FlareSolverr æœåŠ¡æ˜¯å¦æ­£å¸¸\n"
                    f"2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n"
                    f"3. ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®"
                )

    def run(self) -> None:
        """Start the application"""
        # Setup bot
        application = self.bot.setup()

        # Schedule fetching
        self.scheduler.add_job(
            self.fetch_and_notify,
            "interval",
            seconds=self.config.fetch_interval,
            id="data_fetch"
        )

        # Schedule cookie check (ç‹¬ç«‹ä»»åŠ¡)
        if self.config.source_type == SourceType.DISCOURSE and self.config.cookie_check_interval > 0:
            self.scheduler.add_job(
                self._check_cookie_task,
                "interval",
                seconds=self.config.cookie_check_interval,
                id="cookie_check"
            )

        # Run initial fetch after bot starts
        async def post_init(app):
            self.scheduler.start()
            logger.info(f"â° å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨, æ¯ {self.config.fetch_interval} ç§’æ‹‰å–ä¸€æ¬¡")
            if self.config.source_type == SourceType.DISCOURSE and self.config.cookie_check_interval > 0:
                logger.info(f"ğŸ” Cookie æ£€æµ‹å·²å¯åŠ¨, æ¯ {self.config.cookie_check_interval} ç§’æ£€æµ‹ä¸€æ¬¡")
            # Run initial fetch
            await self.fetch_and_notify()

        application.post_init = post_init

        # Start bot (blocking)
        logger.info("ğŸ¤– Telegram Bot å¯åŠ¨ä¸­...")
        application.run_polling()
